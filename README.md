# ollama-pdf-chat
A basic Ollama RAG implementation 

Based on [Duy Huynh's](https://blog.duy-huynh.com/build-your-own-rag-and-run-them-locally/) post.

Requires [Ollama](https://ollama.ai/).

Set the model parameters in `rag.py`. Afterwards, use `streamlit run rag-app.py` to run the chat bot.

A sample environment (built with conda/mamba) can be found in `langpdf.yaml`. 
